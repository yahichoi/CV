{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfe28d03",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.models import Sequential\n",
    "from tensorflow.keras import layers\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "class GAN:\n",
    "    \n",
    "  def __init__(self, img):\n",
    "    \n",
    "    self.img = img\n",
    "    self.rows,self.cols,self.channels = img.shape[1],img.shape[2],img.shape[3]\n",
    "    self.noise_size = 100\n",
    "    \n",
    "    # 생성 - 판별자모델 Discriminator & 생성자모델 Generator\n",
    "    self.create_discriminator()\n",
    "    self.create_generator()\n",
    "    \n",
    "    # 컴파일 - 생성자모델 Discriminator\n",
    "    optimizer = Adam(learning_rate=0.0008)\n",
    "    self.Discriminator.compile(loss='binary_crossentropy', optimizer=optimizer,\n",
    "                               metrics=['accuracy'])\n",
    "    \n",
    "    # 생성 및 컴파일 - 적대적모델 Adversarial  \n",
    "    self.Adversarial = Sequential(\n",
    "       [\n",
    "           self.Generator,\n",
    "           self.Discriminator,      \n",
    "       ])\n",
    "    optimizer = Adam(learning_rate=0.0004)\n",
    "    self.Discriminator.trainable = False\n",
    "    self.Adversarial.compile(loss='binary_crossentropy', optimizer=optimizer,\n",
    "                             metrics=['accuracy'])\n",
    "  \n",
    "  def create_discriminator(self):\n",
    "    depth, dropout = 64, 0.4   \n",
    "    self.Discriminator = Sequential(\n",
    "       [\n",
    "           keras.Input(shape=(self.rows, self.cols, self.channels)),\n",
    "           layers.Conv2D(depth*1, 5, strides=2, padding='same'),\n",
    "           layers.LeakyReLU(alpha=0.2),\n",
    "           layers.Dropout(dropout),          \n",
    "           layers.Conv2D(depth*2, 5, strides=2, padding='same'),\n",
    "           layers.LeakyReLU(alpha=0.2),\n",
    "           layers.Dropout(dropout),           \n",
    "           layers.Conv2D(depth*4, 5, strides=2, padding='same'),\n",
    "           layers.LeakyReLU(alpha=0.2),\n",
    "           layers.Dropout(dropout),          \n",
    "           layers.Conv2D(depth*8, 5, strides=1, padding='same'),\n",
    "           layers.LeakyReLU(alpha=0.2),\n",
    "           layers.Dropout(dropout),           \n",
    "           layers.Flatten(),\n",
    "           layers.Dense(1, activation='sigmoid'),   \n",
    "       ])\n",
    "    self.Discriminator.summary()\n",
    "    return self.Discriminator\n",
    "  \n",
    "  def create_generator(self):\n",
    "    dim, depth, dropout = 7, 256, 0.4  # 256=64+64+64+64\n",
    "    self.Generator = Sequential(\n",
    "       [\n",
    "           keras.Input(shape=(self.noise_size,)),\n",
    "           layers.Dense(dim*dim*depth),\n",
    "           layers.BatchNormalization(momentum=0.9),\n",
    "           layers.Activation('relu'),\n",
    "           layers.Reshape((dim, dim, depth)),\n",
    "           layers.Dropout(dropout),           \n",
    "           layers.UpSampling2D(),\n",
    "           layers.Conv2DTranspose(int(depth/2), 5, padding='same'),\n",
    "           layers.BatchNormalization(momentum=0.9),\n",
    "           layers.Activation('relu'),           \n",
    "           layers.UpSampling2D(),\n",
    "           layers.Conv2DTranspose(int(depth/4), 5, padding='same'),\n",
    "           layers.BatchNormalization(momentum=0.9),\n",
    "           layers.Activation('relu'),           \n",
    "           layers.Conv2DTranspose(int(depth/8), 5, padding='same'),\n",
    "           layers.BatchNormalization(momentum=0.9),\n",
    "           layers.Activation('relu'),           \n",
    "           layers.Conv2DTranspose(1, 5, padding='same'),\n",
    "           layers.Activation('sigmoid'),\n",
    "           \n",
    "       ])\n",
    "    self.Generator.summary()\n",
    "    return self.Generator\n",
    "  \n",
    "  def train(self, batch_size=100):\n",
    "    # 랜덤하게 배치 단위 MNIST 영상 가져오기\n",
    "    images_train = self.img[np.random.randint(0, self.img.shape[0], \n",
    "                   size=batch_size), :, :, :]\n",
    "    \n",
    "    # 잡음을 입력하여 가짜영상 생성\n",
    "    noise = np.random.uniform(-1.0, 1.0, size=[batch_size, self.noise_size])\n",
    "    fake_images = self.Generator.predict(noise)\n",
    "    \n",
    "    # 판별자 Discriminator 학습\n",
    "    x = np.concatenate((images_train, fake_images))\n",
    "    y = np.ones([2*batch_size, 1])\n",
    "    y[batch_size:, :] = 0\n",
    "    self.Discriminator.trainable = True\n",
    "    d_loss = self.Discriminator.train_on_batch(x, y)\n",
    "    \n",
    "    # 생성자 Generator 학습 - 판별자가 fake을 real로 판단하도록\n",
    "    y = np.ones([batch_size, 1])\n",
    "    self.Discriminator.trainable = False\n",
    "    a_loss = self.Adversarial.train_on_batch(noise, y)\n",
    "    \n",
    "    return d_loss, a_loss, fake_images   # end of class GAN\n",
    "\n",
    "#\n",
    "#  MNIST 훈련데이터 읽어와서 정규화 수행\n",
    "mnist = tf.keras.datasets.mnist\n",
    "(x_train, _), (_, _) = mnist.load_data()\n",
    "x_train = x_train.astype('float32') / 255.0\n",
    "rows, cols, channels = 28, 28, 1\n",
    "x_train = x_train.reshape(x_train.shape[0],rows,cols,channels)\n",
    "\n",
    "# GAN 객체 생성 및 초기화\n",
    "gan = GAN(x_train)\n",
    "\n",
    "# 파라미터 세팅\n",
    "epochs, sample_size, batch_size = 20, 10, 100\n",
    "train_per_epoch = x_train.shape[0] // batch_size\n",
    "\n",
    "### 학습 및 출력\n",
    "for epoch in range(0, epochs):  \n",
    "    \n",
    "  ## 학습\n",
    "  for batch in range(0, train_per_epoch):\n",
    "    d_loss, a_loss, fake_images = gan.train(batch_size)      \n",
    "    record = (d_loss[0],100*d_loss[1],a_loss[0],100*a_loss[1])\n",
    "    print('\\nepoch num =', epoch,\" and batch num =\", batch)\n",
    "    print(\"[D loss: %.3f, acc.:%.2f%%][A loss: %.3f, acc.:%.2f%%]\"%record)\n",
    "\n",
    "  ## 생성된 영상 출력\n",
    "  fig, ax = plt.subplots(1, sample_size, figsize=(sample_size, 1))\n",
    "  for i in range(0, sample_size):\n",
    "    ax[i].set_axis_off()\n",
    "    ax[i].imshow(fake_images[i])\n",
    "  plt.show()\n",
    "     "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
