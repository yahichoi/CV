{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd27ea69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FlannBasedMacher() 예제 9.4-2 프로그램\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "img1 = cv2.imread('box.png', 0)  # query Image 로드\n",
    "img2 = cv2.imread('box_in_scene.png', 0) # train Image 로드\n",
    "\n",
    "# Find the keypoints and descriptors with SIFT\n",
    "sift = cv2.xfeatures2d.SIFT_create() \n",
    "keyPoints1, descriptors1 = sift.detectAndCompute(img1, None)\n",
    "keyPoints2, descriptors2 = sift.detectAndCompute(img2, None)\n",
    "\n",
    "# 인덱스 파라미터와 검색 파라미터 설정 \n",
    "FLANN_INDEX_KDTREE = 1\n",
    "index_params = dict(algorithm=FLANN_INDEX_KDTREE, trees=5)\n",
    "search_params = dict(checks=30)\n",
    "\n",
    "# Flann 매처 생성, sorted = Ture(기본값): 정렬해서 반환\n",
    "matcher = cv2.FlannBasedMatcher(index_params, search_params)\n",
    "\n",
    "# 가장 가까운 매칭점 2개씩 검색하여 리스트로 반환\n",
    "matches = matcher.knnMatch(descriptors1, descriptors2, k=2)\n",
    "\n",
    "# 가장 유사한 매칭점이 다른 후보와 확연한 차이가 날 경우\n",
    "# 우수한 매칭점들을 저장할 리스트 생성\n",
    "goodMatches = []     \n",
    "for m, n in matches:   \n",
    "    if m.distance < 0.7 * n.distance:   \n",
    "        goodMatches.append(m)           \n",
    "\n",
    "print(), print('num of goodMatches =', len(goodMatches))\n",
    "print('queryIdx trainIdx distance:')\n",
    "for i in range(5):\n",
    "    print('%5d'%goodMatches[i].queryIdx, '%8d'%goodMatches[i].trainIdx,\n",
    "          '%10.2f'%goodMatches[i].distance)\n",
    "       \n",
    "# 거리값을 기준으로 정렬\n",
    "sorted_GMatches = sorted(goodMatches, key = lambda x : x.distance)\n",
    "\n",
    "print(), print('queryIdx trainIdx distance')\n",
    "for i in range(5):\n",
    "    print('%5d'%sorted_GMatches[i].queryIdx, \n",
    "          '%8d'%sorted_GMatches[i].trainIdx,\n",
    "          '%10.2f'%sorted_GMatches[i].distance)\n",
    "\n",
    "MIN_MATCH_COUNT = 10 # 최소한 검출되어야 하는 매칭점의 개수 세팅\n",
    "if len(goodMatches) > MIN_MATCH_COUNT :      \n",
    "    # 매칭점들을 연결해 두 이미지 간의 매칭 관계 그리기\n",
    "    drawParas = dict(matchColor=(0,255,0),singlePointColor=None,flags=2)\n",
    "    result = cv2.drawMatches(img1, keyPoints1, img2, keyPoints2, \n",
    "                             sorted_GMatches[:15], None, **drawParas)\n",
    "    \n",
    "    # Display the results\n",
    "    cv2.imshow('FLANN result', result)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "else :  # 매칭점이 충분히 검출되지 않았을 경우\n",
    "    print(\"Not enough matches are found \")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
